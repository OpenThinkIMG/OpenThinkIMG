{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mr_eval.utils.utils import *\n",
    "\n",
    "def setup_proxy():\n",
    "    AD_NAME=\"songmingyang\"\n",
    "    encrypted_password=\"dSpydxsxxhKix63HfIFhjwnZLEInXEDawSoMD35G1IT2CygKnHsJqG9ZHbEP\"\n",
    "    new_proxy_address=f\"http://{AD_NAME}:{encrypted_password}@10.1.20.50:23128/\"\n",
    "    # 设置环境变量\n",
    "    os.environ['http_proxy'] = new_proxy_address\n",
    "    os.environ['https_proxy'] = new_proxy_address\n",
    "    os.environ['HTTP_PROXY'] = new_proxy_address\n",
    "    os.environ['HTTPS_PROXY'] = new_proxy_address\n",
    "    \n",
    "setup_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/chartgemma_rl.json\"\n",
    "# val_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/chartgemma_test.json\"\n",
    "# rl_data = load_json_file(rl_data)\n",
    "# val_data = load_json_file(val_data)\n",
    "\n",
    "sft_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/format_validation/opensource_version/chartgemma-combined-sharegpt-llama3.1correct.json\"\n",
    "test_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/eval/OpenThinkIMG-Chart-Test-1000/chartgemma_test.json\"\n",
    "rl_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/eval/openthinkimg/chartgemma_rl.json\"\n",
    "\n",
    "sft_data = load_json_file(sft_data)\n",
    "test_data = load_json_file(test_data)\n",
    "rl_data = load_json_file(rl_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from datasets import Dataset, DatasetDict, Sequence\n",
    "from datasets import Image as ImageData\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "\n",
    "MAPPING = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "\n",
    "def generate_data_rl(data_list: List):\n",
    "    for item in data_list:\n",
    "        image_path = item[\"image_path\"]\n",
    "        question = item[\"question\"]\n",
    "        label = item[\"label\"]\n",
    "        \n",
    "        image = Image.open(image_path, \"r\").convert(\"RGB\")\n",
    " \n",
    "            \n",
    "            \n",
    "        yield {\n",
    "            \"image\": image,\n",
    "            \"question\": question,\n",
    "            \"label\": label,\n",
    "        }\n",
    "\n",
    "def generate_data_sft(data_list: List):\n",
    "    for item in data_list:\n",
    "        conversations = item[\"conversations\"]\n",
    "        images = item[\"images\"]\n",
    "        \n",
    "        image_pils = []\n",
    "        for image_path in images:\n",
    "            image = Image.open(image_path, \"r\").convert(\"RGB\")\n",
    "            image_pils.append(image)\n",
    "            \n",
    "            \n",
    "        yield {\n",
    "            \"images\": image_pils,\n",
    "            \"conversations\": conversations,\n",
    "        }\n",
    "        \n",
    "def generate_data_test(data_list: List):\n",
    "    for item in data_list:\n",
    "        image_path = item[\"image_path\"]\n",
    "        question = item[\"question\"]\n",
    "        label = item[\"label\"].split(\"<answer>\")[-1].split(\"</answer>\")[0].replace(\"\\\"\",\"\").strip()\n",
    "        \n",
    "        image = Image.open(image_path, \"r\").convert(\"RGB\")\n",
    " \n",
    "            \n",
    "            \n",
    "        yield {\n",
    "            \"image\": image,\n",
    "            \"question\": question,\n",
    "            \"label\": label,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2942 examples [03:06, 15.79 examples/s] \n",
      "Casting the dataset: 100%|██████████| 2942/2942 [00:00<00:00, 6232.96 examples/s] \n",
      "Generating train split: 994 examples [00:20, 49.52 examples/s] \n",
      "Generating train split: 14501 examples [07:46, 31.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = Dataset.from_generator(generate_data_sft, gen_kwargs={\"data_list\": sft_data}).cast_column(\"images\", Sequence(ImageData()))\n",
    "testset = Dataset.from_generator(generate_data_test, gen_kwargs={\"data_list\": test_data}).cast_column(\"image\", ImageData())\n",
    "rlset = Dataset.from_generator(generate_data_rl, gen_kwargs={\"data_list\": rl_data}).cast_column(\"image\", ImageData())\n",
    "# valset = Dataset.from_generator(generate_data, gen_kwargs={\"data_list\": val_data})\n",
    "\n",
    "\n",
    "\n",
    "dataset = DatasetDict({\"sft\": trainset, \"test\": testset, \"rl\":rlset})\n",
    "# dataset.push_to_hub(\"hitsmy/toolrl_v1_gemmareachqa\", private=False, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    sft: Dataset({\n",
       "        features: ['images', 'conversations'],\n",
       "        num_rows: 2942\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'question', 'label'],\n",
       "        num_rows: 994\n",
       "    })\n",
       "    rl: Dataset({\n",
       "        features: ['image', 'question', 'label'],\n",
       "        num_rows: 14501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7251/7251 [00:00<00:00, 10000.40 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 73/73 [00:00<00:00, 214.74ba/s]\n",
      "Map: 100%|██████████| 7250/7250 [00:00<00:00, 10055.74 examples/s]6.42s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 73/73 [00:00<00:00, 237.53ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:25<00:00, 12.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/hitsmy/OpenThinkIMG-Chart-RL-14501/commit/b70eb06c1b4a32dfedc7f9e9ea8fb022e80324e3', commit_message='Upload dataset', commit_description='', oid='b70eb06c1b4a32dfedc7f9e9ea8fb022e80324e3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/hitsmy/OpenThinkIMG-Chart-RL-14501', endpoint='https://huggingface.co', repo_type='dataset', repo_id='hitsmy/OpenThinkIMG-Chart-RL-14501'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlset.push_to_hub(\"hitsmy/OpenThinkIMG-Chart-RL-14501\", private=False, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'label'],\n",
       "    num_rows: 14501\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['images', 'conversations'],\n",
       "    num_rows: 2942\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
