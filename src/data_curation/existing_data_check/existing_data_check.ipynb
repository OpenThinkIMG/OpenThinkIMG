{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2942"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mr_eval.utils.utils import *\n",
    "from typing import List, Dict, Any\n",
    "sft_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/select/chartgemma-reachqa-combined-sharegpt.json\"\n",
    "sft_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/format_validation/chartgemma-reachqa-combined-sharegpt-llama3.1correct.json\"\n",
    "sft_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/format_validation/opensource_version/chartgemma-combined-sharegpt.json\"\n",
    "sft_data = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/reasoning/tool_dataset/datasets/chargemma_final/format_validation/opensource_version/chartgemma-combined-sharegpt-llama3.1correct.json\"\n",
    "sft_data = load_json_file(sft_data)\n",
    "len(sft_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(predict_str: List, ground_truth: str):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format, in this case, if it contains the word 'Terminate'.\"\"\"\n",
    "    reward = 0.0\n",
    "    answer = None\n",
    "    sub_format_rewards = []\n",
    "    for pstr in predict_str:\n",
    "        try:\n",
    "            current_reward = 0.0\n",
    "            temp_dict = json.loads(pstr)\n",
    "            assert \"thought\" in temp_dict and \"actions\" in temp_dict\n",
    "            \n",
    "            current_reward = 1.0\n",
    "        except:\n",
    "            current_reward = 0.0\n",
    "        sub_format_rewards.append(current_reward)\n",
    "        \n",
    "    reward = sum(sub_format_rewards) / len(sub_format_rewards) if sub_format_rewards else 0.0\n",
    "    \n",
    "    last_pstr = predict_str[-1]\n",
    "    try:\n",
    "        temp_dict = json.loads(last_pstr)\n",
    "        assert \"thought\" in temp_dict and \"action\" in temp_dict\n",
    "        action = temp_dict[\"action\"][-1]\n",
    "        assert action[\"name\"] == \"Terminate\"\n",
    "        answer = action[\"arguments\"][\"ans\"]\n",
    "    except:\n",
    "        answer = None\n",
    "\n",
    "    return answer, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': 'You are a visual assistant capable of generating and solving steps for chart-based reasoning. Your goal is to answer chart-related questions. You can rely on your own capabilities or use external tools to assist in solving. The available actions include: OCR, Point, DrawHorizontalLineByY, DrawVerticalLineByX, ZoomInSubfigure, SegmentRegionAroundPoint, and Terminate.\\nYour output should be in a strict JSON format as follows:\\n{\"thought\": \"the reasoning process\", \"actions\": [{\"name\": \"action\", \"arguments\": {\"argument1\": \"value1\", \"argument2\": \"value2\"}}]}\\n\\n<image>\\n\\nQuestion: Look at Female Householders with related children under 18, Find the red bar, its value 20%, What is that bar  ?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '{\"thought\": \"To identify the label of the red bar representing 20% in the \\\\\"Female Householders with related children under 18\\\\\" category, I need to reference the legend in the chart that correlates colors with education categories. The red color needs to be matched with its corresponding label.\", \"actions\": []}'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Look at Female Householders with related children under 18, Find the red bar, its value 20%, What is that bar  ?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '{\"thought\": \"Extract text from the legend to identify what the red color represents.\", \"actions\": [{\"name\": \"OCR\", \"arguments\": {\"image\": \"img_1\"}}]}'},\n",
       "  {'from': 'human',\n",
       "   'value': \"OBSERVATION:\\nOCR model outputs: ['60%', '503', '40%', '35%', '', '29%', '30%', '26%', 'è©ˆ', '20%', '20%', '203', '11%', '10%', 'Femal householders With rElated', 'Married COUPIes with related children', 'Jhouseholds', 'Children UnJET', 'Under 15', 'Less than', 'high school diploma', 'High school diploma', 'Some college', 'no degree', 'ASSOClate', 'degree', 'Bachelors degree Or higher', 'SEzisz= 2021', 'AJCitionsllnTormaon', 'ShOwsJUrC=']\\nPlease summarize the model outputs and answer my first question.\"},\n",
       "  {'from': 'gpt',\n",
       "   'value': '{\"thought\": \"Find the label associated with the red color, which corresponds to the 20% value.\", \"actions\": []}'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Look at Female Householders with related children under 18, Find the red bar, its value 20%, What is that bar  ?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '{\"thought\": \"The red bar representing 20% is for \\'Associate degree\\'.\", \"actions\": [{\"name\": \"Terminate\", \"arguments\": {\"ans\": \"Associate degree\"}}]}'}],\n",
       " 'images': ['/mnt/petrelfs/share_data/songmingyang/haoyunzhuo/home/mmtool/training_data/images/tool_auged_v3/chartgemma/image_2131/0.png']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_data[0][\"conversations\"][1][\"value\"]\n",
    "sft_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average format accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "format_acc_values = []\n",
    "\n",
    "for item in sft_data:\n",
    "    conversations = item[\"conversations\"]\n",
    "    model_outputs = []\n",
    "    for conv in conversations:\n",
    "        if conv[\"from\"] == \"gpt\":\n",
    "            model_response = conv[\"value\"]\n",
    "            model_outputs.append(model_response)\n",
    "    format_acc = format_reward(model_outputs, None)[1]\n",
    "    if format_acc == 1.0:\n",
    "        \n",
    "        format_acc_values.append(format_acc)\n",
    "    else:\n",
    "        format_acc_values.append(0)\n",
    "\n",
    "max_format_acc = max(format_acc_values)\n",
    "min_format_acc = min(format_acc_values)\n",
    "mean_format_acc = sum(format_acc_values) / len(format_acc_values)\n",
    "print(f\"Average format accuracy: {mean_format_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average format accuracy: 0.9963\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "format_acc_values = []\n",
    "\n",
    "for item in sft_data:\n",
    "    conversations = item[\"conversations\"]\n",
    "    for conv in conversations:\n",
    "        if conv[\"from\"] == \"gpt\":\n",
    "            model_response = conv[\"value\"]\n",
    "            try:\n",
    "                temp_dict = json.loads(model_response)\n",
    "                thoughts = temp_dict[\"thought\"]\n",
    "                actions = temp_dict[\"actions\"]\n",
    "                format_acc_values.append(1)\n",
    "            except:\n",
    "                format_acc_values.append(0)\n",
    "\n",
    "max_format_acc = max(format_acc_values)\n",
    "min_format_acc = min(format_acc_values)\n",
    "mean_format_acc = sum(format_acc_values) / len(format_acc_values)\n",
    "print(f\"Average format accuracy: {mean_format_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
